import torch as tr
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import time
import math
from collections import OrderedDict
from Model_Base2 import *
from torch.nn.utils import weight_norm

import torch
import torch.nn as nn
import torch.nn.functional as F

class GraphAttentionNetwork(nn.Module):
    def __init__(self, in_features, out_features, num_heads=4, dropout=0.2):
        super(GraphAttentionNetwork, self).__init__()
        self.num_heads = num_heads
        self.attention = nn.MultiheadAttention(embed_dim=out_features, num_heads=num_heads, batch_first=True)
        self.fc = nn.Linear(in_features, out_features)
        self.dropout = nn.Dropout(dropout)
        self.norm = nn.LayerNorm(out_features)

    def forward(self, x):
        # x: [batch_size, num_nodes, features]
        x = self.fc(x)  # Linear transformation
        x = self.dropout(x)
        x_t = x.reshape(x.size(0), -1, x.size(-1))  # 调整为 [batch_size, seq_length, embed_dim]
        attn_out, _ = self.attention(x_t, x_t, x_t)  # Self-attention
        attn_out = self.norm(attn_out + x_t)  # Residual connection + LayerNorm
        return attn_out



# SE 模块用于通道注意力（可以直接复用之前定义的 SELayer）
class SELayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.expand_as(x)

# 用于去除卷积右侧多余填充，保持时序长度不变
class Chomp1d(nn.Module):
    def __init__(self, chomp_size):
        super(Chomp1d, self).__init__()
        self.chomp_size = chomp_size

    def forward(self, x):
        return x[:, :, :-self.chomp_size].contiguous()

# 深度可分离卷积，将标准卷积分解为 depthwise 和 pointwise 两步
class DepthwiseSeparableConv1d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):
        super(DepthwiseSeparableConv1d, self).__init__()
        # 对内部卷积分别应用 weight_norm
        self.depthwise = weight_norm(
            nn.Conv1d(in_channels, in_channels, kernel_size,
                      stride=stride, padding=padding, dilation=dilation,
                      groups=in_channels, bias=False), name="weight")
        self.pointwise = weight_norm(
            nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False), name="weight")

    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        return x


class MultiScaleTCNBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_sizes=[3, 5, 7], dilations=[1, 2, 4], dropout=0.2):
        super(MultiScaleTCNBlock, self).__init__()
        assert len(kernel_sizes) == len(dilations)

        self.branches = nn.ModuleList()
        for k, d in zip(kernel_sizes, dilations):
            padding = (k - 1) * d
            branch = nn.Sequential(
                DepthwiseSeparableConv1d(in_channels, out_channels, kernel_size=k, dilation=d, padding=padding),
                Chomp1d(padding),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout)
            )
            self.branches.append(branch)

        self.merge_conv = nn.Conv1d(out_channels * len(kernel_sizes), out_channels, kernel_size=1)
        self.ff = nn.Sequential(
            nn.Conv1d(out_channels, out_channels, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout)
        )
        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()
        self.relu = nn.ReLU(inplace=True)

        self.attn = nn.MultiheadAttention(embed_dim=out_channels, num_heads=4, batch_first=True)
        self.norm = nn.LayerNorm(out_channels)  # 添加 LayerNorm 层

    def forward(self, x):
        branch_outs = [branch(x) for branch in self.branches]
        out = torch.cat(branch_outs, dim=1)  # (B, C * num_branches, T)
        out = self.merge_conv(out)
        out = self.ff(out)

        # Multi-head Attention: transpose to (B, T, C) for attention
        out_t = out.transpose(1, 2)  # (B, T, C)
        attn_out, _ = self.attn(out_t, out_t, out_t)  # Self-attention
        attn_out = self.norm(attn_out + out_t)  # Residual + LayerNorm
        out = attn_out.transpose(1, 2)  # Back to (B, C, T)

        residual = self.downsample(x)
        return self.relu(out + residual)

class ModernTCN(nn.Module):
    def __init__(self, input_channels, kernel_size=3, dropout=0.2):
        super().__init__()
        num_channels = [32, 32, 32]
        layers = []
        in_channels = input_channels

        for i, out_channels in enumerate(num_channels):
            layers.append(MultiScaleTCNBlock(in_channels, out_channels,
                                             kernel_sizes=[3, 5, 7],
                                             dilations=[1, 2, 4],
                                             dropout=dropout))
            in_channels = out_channels

        self.network = nn.Sequential(*layers)
        self.se1 = SELayer(num_channels[-1], reduction=4)

    def forward(self, x):
        out = self.network(x)
        out = self.se1(out)
        out = nn.AdaptiveAvgPool1d(16)(out)
        out = torch.flatten(out, start_dim=1)
        return out

class ModernTCNBlock(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, dilation=1, dropout=0.2):
        super(ModernTCNBlock, self).__init__()
        padding = (kernel_size - 1) * dilation
        self.conv = DepthwiseSeparableConv1d(in_channels, out_channels, kernel_size,
                                       stride=1, padding=padding, dilation=dilation)

        self.chomp = Chomp1d(padding)
        # 由于输入为 (batch, channels, seq_len)，LayerNorm 需转置为 (batch, seq_len, channels)
        self.layer_norm = nn.LayerNorm(out_channels)
        self.dropout = nn.Dropout(dropout)
        # 卷积前馈网络（1×1卷积 + 激活）
        self.ff = nn.Sequential(
            nn.Conv1d(out_channels, out_channels, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Dropout(dropout)
        )
        self.downsample = nn.Conv1d(in_channels, out_channels, kernel_size=1) if in_channels != out_channels else nn.Identity()
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        out = self.conv(x)
        out = self.chomp(out)
        # 转置后应用 LayerNorm，再转回
        out = self.layer_norm(out.transpose(1, 2)).transpose(1, 2)
        out = self.dropout(out)
        ff_out = self.ff(out)
        residual = self.downsample(x)
        return self.relu(ff_out + residual)

#############################################
# HierarchicalFusion：对两路内部特征进行融合
#############################################
class HierarchicalFusion(nn.Module):
    def __init__(self, in_features, hidden_dim):
        """
        in_features: 单一路径输入特征的维度
        hidden_dim: 融合后输出的维度
        """
        super(HierarchicalFusion, self).__init__()
        self.fuse = nn.Sequential(
            nn.Linear(20480, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(inplace=True)
        )

    def forward(self, f1, f2):
        # f1, f2: [bs, in_features]
        x = torch.cat([f1, f2], dim=-1)
        return self.fuse(x)


#############################################
# TwoBranchFusion：对两路输入进行注意力加权融合
#############################################
class TwoBranchFusion(nn.Module):
    def __init__(self, emb_size):
        super(TwoBranchFusion, self).__init__()
        self.weight = nn.Parameter(torch.randn(emb_size, 1), requires_grad=True)
        self.softmax = nn.Softmax(dim=-1)

    def forward(self, f1, f2):
        # f1, f2: [bs, emb_size]
        score1 = f1 @ self.weight  # [bs, 1]
        score2 = f2 @ self.weight  # [bs, 1]
        scores = tr.cat([score1, score2], dim=-1)  # [bs, 2]
        att_weights = self.softmax(scores)  # [bs, 2]
        fused = f1 * att_weights[:, 0:1] + f2 * att_weights[:, 1:2]
        return fused


#############################################
# Classification Head：利用各分支融合结果生成最终预测
#############################################
class ClassificationHead_FC_STGNN(nn.Module):
    def __init__(self, num_classes, emb_size, dropout=0.5):
        super(ClassificationHead_FC_STGNN, self).__init__()
        self.dropout = dropout
        # 对时域、频域以及最终融合后的特征分别映射到类别数
        self.fc_time = nn.Linear(emb_size, num_classes)
        self.fc_freq = nn.Linear(emb_size, num_classes)
        self.fc_final = nn.Linear(emb_size, num_classes)
        self.w = nn.Parameter(torch.Tensor([1.0, 1.0, 0.5]), requires_grad=True)

    def forward(self, fused_time, fused_freq, fused_total):
        out_time = self.fc_time(fused_time)
        out_freq = self.fc_freq(fused_freq)
        out_final = self.fc_final(fused_total)
        exp_w = torch.exp(self.w)
        norm_w = exp_w / torch.sum(exp_w)
        out = out_time * norm_w[0] + out_freq * norm_w[1] + out_final * norm_w[2]
        return out


#############################################
# 更新的 FC_STGNN_HAR 模型（仅展示融合与分类部分）
#############################################
class FC_STGNN_HAR(nn.Module):
    def __init__(self, indim_fea, Conv_out, lstmhidden_dim, lstmout_dim, conv_kernel, hidden_dim,
                 time_length, num_node, num_windows, moving_window, stride, decay, pooling_choice, n_class):
        super(FC_STGNN_HAR, self).__init__()
        # 省略前面的时域与频域分支特征提取代码，假设与之前一致
        self.nonlin_map = Feature_extractor_1DCNN_HAR_SSC(1, lstmhidden_dim, lstmout_dim, kernel_size=conv_kernel)
        self.nonlin_map2 = nn.Sequential(
            nn.Linear(126, 2 * hidden_dim),
            nn.BatchNorm1d(2 * hidden_dim)
        )
        self.positional_encoding = PositionalEncoding(2 * hidden_dim, 0.1, max_len=5000)
        self.MPNN1 = GraphConvpoolMPNN_block_v6(2 * hidden_dim, hidden_dim, num_node, time_length,
                                                time_window_size=moving_window[0], stride=stride[0],
                                                decay=decay, pool_choice=pooling_choice)
        self.MPNN2 = GraphConvpoolMPNN_block_v6(2 * hidden_dim, hidden_dim, num_node, time_length,
                                                time_window_size=moving_window[1], stride=stride[1],
                                                decay=decay, pool_choice=pooling_choice)
        self.freq_nonlin_map = Feature_extractor_1DCNN_HAR_SSC(1, lstmhidden_dim, lstmout_dim, kernel_size=conv_kernel)
        self.freq_nonlin_map2 = nn.Sequential(
            nn.Linear(126, 2 * hidden_dim),
            nn.BatchNorm1d(2 * hidden_dim)
        )
        self.freq_positional_encoding = PositionalEncoding(2 * hidden_dim, 0.1, max_len=5000)

        self.freq_GAT1 = GraphAttentionNetwork(2 * hidden_dim, hidden_dim, num_heads=4, dropout=0.2)
        self.freq_GAT2 = GraphAttentionNetwork(2 * hidden_dim, hidden_dim, num_heads=4, dropout=0.2)

        self.freq_MPNN1 = GraphConvpoolMPNN_block_v6(2 * hidden_dim, hidden_dim, num_node, time_length,
                                                     time_window_size=moving_window[0], stride=stride[0],
                                                     decay=decay, pool_choice=pooling_choice)
        self.freq_MPNN2 = GraphConvpoolMPNN_block_v6(2 * hidden_dim, hidden_dim, num_node, time_length,
                                                     time_window_size=moving_window[1], stride=stride[1],
                                                     decay=decay, pool_choice=pooling_choice)

        # Hierarchical fusion 对时域内部融合（features_time1 和 features_time2）
        self.time_hier_fusion = HierarchicalFusion(in_features=self.fusion_dim_final, hidden_dim=self.fusion_dim_final)
        # Hierarchical fusion 对频域内部融合（features_freq1 和 features_freq2）
        self.freq_hier_fusion = HierarchicalFusion(in_features=self.fusion_dim_final, hidden_dim=self.fusion_dim_final)
        # 最终融合：融合时域与频域融合后的特征（两者维度均为 fusion_dim_final）
        self.final_fusion = TwoBranchFusion(emb_size=self.fusion_dim_final)

        # 分类头
        self.classify = ClassificationHead_FC_STGNN(n_class, emb_size=self.fusion_dim_final, dropout=0.5)

        self.model = Model(flag=False, num_channels=32, seq_length=800,
                      num_classes=2, periods=[10, 20, 30, 40, 50], embed_dim=32,
                      embed_dim_t=128, num_heads=4, ff_dim=128, num_layers=1)

        self.modern_tcn = ModernTCN(input_channels=32, kernel_size=3, dropout=0.2)

    def forward(self, X):
        # 假设 X 尺寸为 [bs, tlen, num_node_total, dimension]，
        # 并将其分为时域数据 X1 和频域数据 X2


        X1 = X[:, :, :X.size(2) // 2, :]
        X1 = torch.transpose(X1, 1,2)
        shape = X1.size()
        X1 = X1.reshape(shape[0],shape[1],-1)

        fused_time = self.modern_tcn(X1)  # [bs, num_node, tlen, embed_dim]

        X2 = X[:, :, X.size(2) // 2:, :]

        # 以下为频域分支的特征提取
        bs, tlen, num_node, dimension = X2.size()
        X_freq = tr.reshape(X2, [bs * tlen * num_node, dimension, 1])
        X_freq = self.freq_nonlin_map(X_freq)
        X_freq = tr.reshape(X_freq, [bs * tlen * num_node, -1])
        X_freq = self.freq_nonlin_map2(X_freq)
        X_freq = tr.reshape(X_freq, [bs, tlen, num_node, -1])
        X_freq = tr.reshape(X_freq, [bs, tlen, num_node, -1])
        X_freq = tr.transpose(X_freq, 1, 2)
        X_freq = tr.reshape(X_freq, [bs * num_node, tlen, -1])
        X_freq = self.freq_positional_encoding(X_freq)
        X_freq = tr.reshape(X_freq, [bs, num_node, tlen, -1])
        X_freq = tr.transpose(X_freq, 1, 2)
        A_input_freq = X_freq
        MPNN_output_freq1 = self.freq_GAT1(A_input_freq)  # Replace MPNN1 with GAT1
        MPNN_output_freq2 = self.freq_GAT2(A_input_freq)  # Repl
        features_freq1 = tr.reshape(MPNN_output_freq1, [bs, -1])  # [bs, fusion_dim_final]
        features_freq2 = tr.reshape(MPNN_output_freq2, [bs, -1])  # [bs, fusion_dim_final]

        # 分别对时域和频域内部进行 Hierarchical fusion
        fused_freq = self.freq_hier_fusion(features_freq1, features_freq2)  # [bs, fusion_dim_final]
        # 最终融合时域与频域的融合结果
        fused_total = self.final_fusion(fused_time, fused_freq)  # [bs, fusion_dim_final]

        # 利用分类头进行多分支加权融合预测
        outputs = self.classify(fused_time, fused_freq, fused_total)
        return outputs



def fft_transform(x):
    fft_signal = np.fft.fft(x, axis=-1)
    real_part = np.real(fft_signal)
    half_real_part = real_part[..., :real_part.shape[-1] // 2]
    return half_real_part







#### Best for SSC
class FC_STGNN_SSC(nn.Module):
    def __init__(self, indim_fea, Conv_out, lstmhidden_dim, lstmout_dim, conv_kernel,hidden_dim, time_length, num_node, num_windows, moving_window,stride,decay, pooling_choice, n_class,dropout):
        super(FC_STGNN_SSC, self).__init__()
        self.nonlin_map = Feature_extractor_1DCNN_HAR_SSC(1, lstmhidden_dim, lstmout_dim,kernel_size=conv_kernel,dropout=dropout)
        self.nonlin_map2 = nn.Sequential(
            nn.Linear(lstmout_dim*Conv_out, 2*hidden_dim),
            nn.BatchNorm1d(2*hidden_dim)
        )

        self.positional_encoding = PositionalEncoding(2*hidden_dim,0.1,max_len=5000)

        self.MPNN1 = GraphConvpoolMPNN_block_v6(2*hidden_dim, hidden_dim, num_node, time_length, time_window_size=moving_window[0], stride=stride[0], decay = decay, pool_choice=pooling_choice)
        self.MPNN2 = GraphConvpoolMPNN_block_v6(2*hidden_dim, hidden_dim, num_node, time_length, time_window_size=moving_window[1], stride=stride[1], decay = decay, pool_choice=pooling_choice)


        self.fc = nn.Sequential(OrderedDict([
            ('fc1', nn.Linear(hidden_dim * num_windows * num_node, 2*hidden_dim)),
            ('relu1', nn.ReLU(inplace=True)),
            ('fc2', nn.Linear(2*hidden_dim, 2*hidden_dim)),
            ('relu2', nn.ReLU(inplace=True)),
            ('fc3', nn.Linear(2*hidden_dim, hidden_dim)),
            ('relu3', nn.ReLU(inplace=True)),
            ('fc4', nn.Linear(hidden_dim, n_class)),

        ]))



    def forward(self, X):
        # print(X.size())
        bs, tlen, num_node, dimension = X.size()

        ### Graph Generation
        A_input = tr.reshape(X, [bs*tlen*num_node, dimension, 1])
        A_input_ = self.nonlin_map(A_input)
        A_input_ = tr.reshape(A_input_, [bs*tlen*num_node,-1])
        A_input_ = self.nonlin_map2(A_input_)
        A_input_ = tr.reshape(A_input_, [bs, tlen,num_node,-1])

        ## positional encoding before mapping starting
        X_ = tr.reshape(A_input_, [bs,tlen,num_node, -1])
        X_ = tr.transpose(X_,1,2)
        X_ = tr.reshape(X_,[bs*num_node, tlen, -1])
        X_ = self.positional_encoding(X_)
        X_ = tr.reshape(X_,[bs,num_node, tlen, -1])
        X_ = tr.transpose(X_,1,2)
        A_input_ = X_

        ## positional encoding before mapping ending

        MPNN_output1 = self.MPNN1(A_input_)
        MPNN_output2 = self.MPNN2(A_input_)


        features1 = tr.reshape(MPNN_output1, [bs, -1])
        features2 = tr.reshape(MPNN_output2, [bs, -1])

        features = tr.cat([features1,features2],-1)

        features = self.fc(features)

        return features
